{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('100_Unique_QA_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Who directed the movie 'Titanic'?</td>\n",
       "      <td>JamesCameron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Which superhero is also known as the Dark Knight?</td>\n",
       "      <td>Batman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>What is the capital of Brazil?</td>\n",
       "      <td>Brasilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Which fruit is known as the king of fruits?</td>\n",
       "      <td>Mango</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Which country is known for the Eiffel Tower?</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question        answer\n",
       "0                      What is the capital of France?         Paris\n",
       "1                     What is the capital of Germany?        Berlin\n",
       "2                  Who wrote 'To Kill a Mockingbird'?    Harper-Lee\n",
       "3     What is the largest planet in our solar system?       Jupiter\n",
       "4      What is the boiling point of water in Celsius?           100\n",
       "..                                                ...           ...\n",
       "85                  Who directed the movie 'Titanic'?  JamesCameron\n",
       "86  Which superhero is also known as the Dark Knight?        Batman\n",
       "87                     What is the capital of Brazil?      Brasilia\n",
       "88        Which fruit is known as the king of fruits?         Mango\n",
       "89       Which country is known for the Eiffel Tower?        France\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tokenize \n",
    "def toeknize(text):\n",
    "    text=text.lower()\n",
    "    text=text.replace('?','')\n",
    "    text=text.replace(\"'\",'')\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'your', 'name']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toeknize('What is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab\n",
    "vocab={'<unk>':0}\n",
    "\n",
    "def build_vocab(row):\n",
    "    tokenized_question=toeknize(row['question'])\n",
    "    tokenized_answer=toeknize(row['answer'])\n",
    "\n",
    "    merged_token=tokenized_question+tokenized_answer\n",
    "\n",
    "    for token in merged_token:\n",
    "        if token not in vocab:\n",
    "            vocab[token]=len(vocab)\n",
    "            \n",
    "    print(tokenized_question,tokenized_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'the', 'capital', 'of', 'france'] ['paris']\n",
      "['what', 'is', 'the', 'capital', 'of', 'germany'] ['berlin']\n",
      "['who', 'wrote', 'to', 'kill', 'a', 'mockingbird'] ['harper-lee']\n",
      "['what', 'is', 'the', 'largest', 'planet', 'in', 'our', 'solar', 'system'] ['jupiter']\n",
      "['what', 'is', 'the', 'boiling', 'point', 'of', 'water', 'in', 'celsius'] ['100']\n",
      "['who', 'painted', 'the', 'mona', 'lisa'] ['leonardo-da-vinci']\n",
      "['what', 'is', 'the', 'square', 'root', 'of', '64'] ['8']\n",
      "['what', 'is', 'the', 'chemical', 'symbol', 'for', 'gold'] ['au']\n",
      "['which', 'year', 'did', 'world', 'war', 'ii', 'end'] ['1945']\n",
      "['what', 'is', 'the', 'longest', 'river', 'in', 'the', 'world'] ['nile']\n",
      "['what', 'is', 'the', 'capital', 'of', 'japan'] ['tokyo']\n",
      "['who', 'developed', 'the', 'theory', 'of', 'relativity'] ['albert-einstein']\n",
      "['what', 'is', 'the', 'freezing', 'point', 'of', 'water', 'in', 'fahrenheit'] ['32']\n",
      "['which', 'planet', 'is', 'known', 'as', 'the', 'red', 'planet'] ['mars']\n",
      "['who', 'is', 'the', 'author', 'of', '1984'] ['george-orwell']\n",
      "['what', 'is', 'the', 'currency', 'of', 'the', 'united', 'kingdom'] ['pound']\n",
      "['what', 'is', 'the', 'capital', 'of', 'india'] ['delhi']\n",
      "['who', 'discovered', 'gravity'] ['newton']\n",
      "['how', 'many', 'continents', 'are', 'there', 'on', 'earth'] ['7']\n",
      "['which', 'gas', 'do', 'plants', 'use', 'for', 'photosynthesis'] ['co2']\n",
      "['what', 'is', 'the', 'smallest', 'prime', 'number'] ['2']\n",
      "['who', 'invented', 'the', 'telephone'] ['alexander-graham-bell']\n",
      "['what', 'is', 'the', 'capital', 'of', 'australia'] ['canberra']\n",
      "['which', 'ocean', 'is', 'the', 'largest'] ['pacific-ocean']\n",
      "['what', 'is', 'the', 'speed', 'of', 'light', 'in', 'vacuum'] ['299,792,458m/s']\n",
      "['which', 'language', 'is', 'spoken', 'in', 'brazil'] ['portuguese']\n",
      "['who', 'discovered', 'penicillin'] ['alexander-fleming']\n",
      "['what', 'is', 'the', 'capital', 'of', 'canada'] ['ottawa']\n",
      "['what', 'is', 'the', 'largest', 'mammal', 'on', 'earth'] ['whale']\n",
      "['which', 'element', 'has', 'the', 'atomic', 'number', '1'] ['hydrogen']\n",
      "['what', 'is', 'the', 'tallest', 'mountain', 'in', 'the', 'world'] ['everest']\n",
      "['which', 'city', 'is', 'known', 'as', 'the', 'big', 'apple'] ['newyork']\n",
      "['how', 'many', 'planets', 'are', 'in', 'the', 'solar', 'system'] ['8']\n",
      "['who', 'painted', 'starry', 'night'] ['vangogh']\n",
      "['what', 'is', 'the', 'chemical', 'formula', 'of', 'water'] ['h2o']\n",
      "['what', 'is', 'the', 'capital', 'of', 'italy'] ['rome']\n",
      "['which', 'country', 'is', 'famous', 'for', 'sushi'] ['japan']\n",
      "['who', 'was', 'the', 'first', 'person', 'to', 'step', 'on', 'the', 'moon'] ['armstrong']\n",
      "['what', 'is', 'the', 'main', 'ingredient', 'in', 'guacamole'] ['avocado']\n",
      "['how', 'many', 'sides', 'does', 'a', 'hexagon', 'have'] ['6']\n",
      "['what', 'is', 'the', 'currency', 'of', 'china'] ['yuan']\n",
      "['who', 'wrote', 'pride', 'and', 'prejudice'] ['jane-austen']\n",
      "['what', 'is', 'the', 'chemical', 'symbol', 'for', 'iron'] ['fe']\n",
      "['what', 'is', 'the', 'hardest', 'natural', 'substance', 'on', 'earth'] ['diamond']\n",
      "['which', 'continent', 'is', 'the', 'largest', 'by', 'area'] ['asia']\n",
      "['who', 'was', 'the', 'first', 'president', 'of', 'the', 'united', 'states'] ['george-washington']\n",
      "['which', 'bird', 'is', 'known', 'for', 'its', 'ability', 'to', 'mimic', 'sounds'] ['parrot']\n",
      "['what', 'is', 'the', 'longest-running', 'animated', 'tv', 'show'] ['simpsons']\n",
      "['what', 'is', 'the', 'smallest', 'country', 'in', 'the', 'world'] ['vaticancity']\n",
      "['which', 'planet', 'has', 'the', 'most', 'moons'] ['saturn']\n",
      "['who', 'wrote', 'romeo', 'and', 'juliet'] ['shakespeare']\n",
      "['what', 'is', 'the', 'main', 'gas', 'in', 'earths', 'atmosphere'] ['nitrogen']\n",
      "['how', 'many', 'bones', 'are', 'in', 'the', 'adult', 'human', 'body'] ['206']\n",
      "['which', 'metal', 'is', 'a', 'liquid', 'at', 'room', 'temperature'] ['mercury']\n",
      "['what', 'is', 'the', 'capital', 'of', 'russia'] ['moscow']\n",
      "['who', 'discovered', 'electricity'] ['benjamin-franklin']\n",
      "['which', 'is', 'the', 'second-largest', 'country', 'by', 'land', 'area'] ['canada']\n",
      "['what', 'is', 'the', 'color', 'of', 'a', 'ripe', 'banana'] ['yellow']\n",
      "['which', 'month', 'has', '28', 'days', 'in', 'a', 'common', 'year'] ['february']\n",
      "['what', 'is', 'the', 'study', 'of', 'living', 'organisms', 'called'] ['biology']\n",
      "['which', 'country', 'is', 'home', 'to', 'the', 'great', 'wall'] ['china']\n",
      "['what', 'do', 'bees', 'collect', 'from', 'flowers'] ['nectar']\n",
      "['what', 'is', 'the', 'opposite', 'of', 'day'] ['night']\n",
      "['what', 'is', 'the', 'capital', 'of', 'south', 'korea'] ['seoul']\n",
      "['who', 'invented', 'the', 'light', 'bulb'] ['edison']\n",
      "['which', 'gas', 'do', 'humans', 'breathe', 'in', 'for', 'survival'] ['oxygen']\n",
      "['what', 'is', 'the', 'square', 'root', 'of', '144'] ['12']\n",
      "['which', 'country', 'has', 'the', 'pyramids', 'of', 'giza'] ['egypt']\n",
      "['which', 'sea', 'creature', 'has', 'eight', 'arms'] ['octopus']\n",
      "['which', 'holiday', 'is', 'celebrated', 'on', 'december', '25'] ['christmas']\n",
      "['what', 'is', 'the', 'currency', 'of', 'japan'] ['yen']\n",
      "['how', 'many', 'legs', 'does', 'a', 'spider', 'have'] ['8']\n",
      "['which', 'sport', 'uses', 'a', 'net,', 'ball,', 'and', 'hoop'] ['basketball']\n",
      "['which', 'country', 'is', 'famous', 'for', 'its', 'kangaroos'] ['australia']\n",
      "['who', 'was', 'the', 'first', 'female', 'prime', 'minister', 'of', 'the', 'uk'] ['margaretthatcher']\n",
      "['which', 'is', 'the', 'fastest', 'land', 'animal'] ['cheetah']\n",
      "['what', 'is', 'the', 'first', 'element', 'on', 'the', 'periodic', 'table'] ['hydrogen']\n",
      "['what', 'is', 'the', 'capital', 'of', 'spain'] ['madrid']\n",
      "['which', 'planet', 'is', 'the', 'closest', 'to', 'the', 'sun'] ['mercury']\n",
      "['who', 'is', 'known', 'as', 'the', 'father', 'of', 'computers'] ['charlesbabbage']\n",
      "['what', 'is', 'the', 'capital', 'of', 'mexico'] ['mexicocity']\n",
      "['how', 'many', 'colors', 'are', 'in', 'a', 'rainbow'] ['7']\n",
      "['which', 'musical', 'instrument', 'has', 'black', 'and', 'white', 'keys'] ['piano']\n",
      "['who', 'discovered', 'the', 'americas', 'in', '1492'] ['christophercolumbus']\n",
      "['which', 'disney', 'character', 'has', 'a', 'long', 'nose', 'and', 'grows', 'it', 'when', 'lying'] ['pinocchio']\n",
      "['who', 'directed', 'the', 'movie', 'titanic'] ['jamescameron']\n",
      "['which', 'superhero', 'is', 'also', 'known', 'as', 'the', 'dark', 'knight'] ['batman']\n",
      "['what', 'is', 'the', 'capital', 'of', 'brazil'] ['brasilia']\n",
      "['which', 'fruit', 'is', 'known', 'as', 'the', 'king', 'of', 'fruits'] ['mango']\n",
      "['which', 'country', 'is', 'known', 'for', 'the', 'eiffel', 'tower'] ['france']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  convert words to numerical index\n",
    "df.apply(build_vocab,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index(text,vocab):\n",
    "    index_text=[]\n",
    "\n",
    "    for token in toeknize(text):\n",
    "        if token in vocab:\n",
    "            index_text.append(vocab[token])\n",
    "        else:\n",
    "            index_text.append(vocab['<unk>'])\n",
    "\n",
    "    return index_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 0]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_index('What is your name?',vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self,df,vocab):\n",
    "        self.df=df\n",
    "        self.vocab=vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        numerical_question=text_to_index(self.df.iloc[index]['question'],self.vocab)\n",
    "        numerical_answer=text_to_index(self.df.iloc[index]['answer'],self.vocab)\n",
    "    \n",
    "        return torch.tensor(numerical_question),torch.tensor(numerical_answer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=QADataset(df,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=DataLoader(dataset,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
      "tensor([[10, 75, 76]]) tensor([[77]])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
      "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
      "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
      "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n"
     ]
    }
   ],
   "source": [
    "for question,answer in dataloader:\n",
    "    print(question,answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 50)\n",
    "        self.rnn = nn.RNN(50, 64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "\n",
    "    def forward(self, question):\n",
    "        embedded_question=self.embedding(question)\n",
    "        hidden,final=self.rnn(embedded_question)\n",
    "        output=self.fc(final.squeeze(0))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a: torch.Size([1, 6])\n",
      "shape of b: torch.Size([1, 6, 50])\n",
      "shape of c: torch.Size([1, 6, 64])\n",
      "shape of d: torch.Size([1, 1, 64])\n",
      "shape of e: torch.Size([1, 324])\n"
     ]
    }
   ],
   "source": [
    "x = nn.Embedding(324, embedding_dim=50)\n",
    "y = nn.RNN(50, 64, batch_first=True)\n",
    "z = nn.Linear(64, 324)\n",
    "\n",
    "a = dataset[0][0].reshape(1,6)\n",
    "print(\"shape of a:\", a.shape)\n",
    "b = x(a)\n",
    "print(\"shape of b:\", b.shape)\n",
    "c, d = y(b)\n",
    "print(\"shape of c:\", c.shape)\n",
    "print(\"shape of d:\", d.shape)\n",
    "\n",
    "e = z(d.squeeze(0))\n",
    "\n",
    "print(\"shape of e:\", e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SimpleRNN(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.823628081215753\n",
      "Epoch 2, Loss: 5.12026818063524\n",
      "Epoch 3, Loss: 4.298684496349758\n",
      "Epoch 4, Loss: 3.578390701611837\n",
      "Epoch 5, Loss: 2.9930490281846787\n",
      "Epoch 6, Loss: 2.451018594370948\n",
      "Epoch 7, Loss: 1.9565055476294624\n",
      "Epoch 8, Loss: 1.5165443354182773\n",
      "Epoch 9, Loss: 1.1700683706336552\n",
      "Epoch 10, Loss: 0.894202987684144\n",
      "Epoch 11, Loss: 0.6938120083676445\n",
      "Epoch 12, Loss: 0.5446168579989009\n",
      "Epoch 13, Loss: 0.44009046620792813\n",
      "Epoch 14, Loss: 0.3600018443332778\n",
      "Epoch 15, Loss: 0.29809250699149237\n",
      "Epoch 16, Loss: 0.2537421520385477\n",
      "Epoch 17, Loss: 0.21604839505420792\n",
      "Epoch 18, Loss: 0.18628149992889828\n",
      "Epoch 19, Loss: 0.16274457358651692\n",
      "Epoch 20, Loss: 0.1418845396902826\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for question, answer in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(question)\n",
    "        # reshape output to (batch_size * sequence_length, num_classes)\n",
    "        output = output.view(-1, len(vocab))\n",
    "        # reshape answer to (batch_size * sequence_length)\n",
    "        answer = answer.view(-1)\n",
    "        # calculate loss\n",
    "        loss = criterion(output, answer)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, question, threshold=0.5):\n",
    "\n",
    "  # convert question to numbers\n",
    "  numerical_question = text_to_index(question, vocab)\n",
    "\n",
    "  # tensor\n",
    "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "\n",
    "  # send to model\n",
    "  output = model(question_tensor)\n",
    "\n",
    "  # convert logits to probs\n",
    "  probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "  # find index of max prob\n",
    "  value, index = torch.max(probs, dim=1)\n",
    "  print(\"value is :\",value,\"index is:\", index)\n",
    "  if value < threshold:\n",
    "    print(\"I don't know\")\n",
    "\n",
    "  print(list(vocab.keys())[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input(\"Enter question:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value is : tensor([0.5228], grad_fn=<MaxBackward0>) index is: tensor([54])\n",
      "tokyo\n"
     ]
    }
   ],
   "source": [
    "predict(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
